{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f5bb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7efdea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardit_df = pd.read_excel('Sample_Data_from_IODA_v4 (China Post).xlsx', sheet_name='gls mail cardit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "033a0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.read_excel('Sample_Data_from_IODA_v4 (China Post).xlsx', sheet_name='cardit receptacle event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e1ef0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_excel('Sample_Data_from_IODA_v4 (China Post).xlsx', sheet_name='awb master')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061fc89",
   "metadata": {},
   "source": [
    "## Data Sanitisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd379d",
   "metadata": {},
   "source": [
    "### Cardit Table Sanitisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ba56fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep China Post as post office only\n",
    "Keep first leg only\n",
    "\"\"\"\n",
    "\n",
    "cardit_df = cardit_df[cardit_df['post_office'] == 'China Post']\n",
    "cardit_df = cardit_df[cardit_df['leg_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25d84699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering fields to keep \n",
    "columns_to_keep = [\"dim_cgo_cargo_awb_master_sk\", \"receptacle_charge_weight\", \"shipment_origin\", \"shipment_dest\", \"fct_cgo_gls_mail_cardit_sk\"]\n",
    "\n",
    "cardit_df = cardit_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8205c",
   "metadata": {},
   "source": [
    "### Master Table Sanitisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "623e9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering fields to keep \n",
    "columns_to_keep = [\"dim_cgo_cargo_awb_master_sk\", \"awb_number\"]\n",
    "\n",
    "master_df = master_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242408bd",
   "metadata": {},
   "source": [
    "### Event Table Sanitisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79e8f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep necessary fields first for easier processing\n",
    "columns_to_keep = [\"receptacle_id\", \"leg_number\", \"carrier_code\", \"flight_number\", \"flight_date\", \"shipment_origin\", \"shipment_dest\", \"actual_depart_datetime_local\",\t\"actual_arrive_datetime_local\", \"fct_cgo_gls_mail_cardit_sk\", 'uld_id', 'mail_consign_number']\n",
    "\n",
    "event_df = event_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4057d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove possible \"[Null]\" string values\n",
    "event_df = event_df.replace(\"[Null]\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis will remove flights that have never departed\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where actual_depart_datetime_local is missing\n",
    "# This will remove flights that have never departed\n",
    "event_df = event_df[event_df['actual_depart_datetime_local'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3936505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The same receptacle might have multiple actual_depart_datetime_local. We want to keep the latest departure only\n",
    "\"\"\"\n",
    "\n",
    "# Keep only the row with the latest actual_depart_datetime_local for each receptacle_id\n",
    "event_df = event_df.loc[\n",
    "    event_df.groupby(['receptacle_id', 'leg_number'])['actual_depart_datetime_local'].idxmax()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce90adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ULD_id so that the ULD_id is of the last leg (the leg into the US) for all rows no matter what leg it is (eg leg 1 should have uld_id of the last leg)\n",
    "\n",
    "latest_uld = event_df.sort_values('leg_number').groupby('receptacle_id').last()['uld_id']\n",
    "event_df['uld_id'] = event_df['receptacle_id'].map(latest_uld)\n",
    "\n",
    "event_df.rename(columns={'uld_id': 'last_leg_uld_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create and populate Flight Carrier 1, Flight Number 1, Flight Date 1, actual_depart_datetime 1, actual_arrive_datetime 1\n",
    "Flight Carrier 2, Flight Number 2, Flight Date 2, actual_depart_datetime 2, actual_arrive_datetime 2\n",
    "To n columns\n",
    "\n",
    "Need to dynamically create n columns where n is the max number of legs in the table and populate accordingly\n",
    "Eg if a flight has m legs where m < n, null will be put in for columns m+1, m+2...n\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Find the maximum number of legs in the table (eg some flights can have 2 legs, some can have 3, 4 etc. We want the highest number of legs)\n",
    "leg_counts = event_df.groupby('receptacle_id')['leg_number'].nunique()\n",
    "max_legs = leg_counts.max()\n",
    "\n",
    "for i in range(max_legs):\n",
    "    event_df[f'Flight Carrier {i+1}'] = None\n",
    "    event_df[f'Flight Number {i+1}'] = None\n",
    "    event_df[f'Flight Date {i+1}'] = None\n",
    "    event_df[f'actual_depart_datetime {i+1}'] = None\n",
    "    event_df[f'actual_arrive_datetime {i+1}'] = None\n",
    "\n",
    "\n",
    "\n",
    "# Extract flight_date from actual_depart_datetime_local\n",
    "event_df['flight_date_from_datetime'] = pd.to_datetime(event_df['actual_depart_datetime_local']).dt.date\n",
    "\n",
    "# Create a subset with all columns needed for pivoting\n",
    "pivot_data = event_df[[\n",
    "    'receptacle_id', 'leg_number',\n",
    "    'carrier_code', 'flight_number', 'flight_date_from_datetime',\n",
    "    'actual_depart_datetime_local', 'actual_arrive_datetime_local'\n",
    "]]\n",
    "\n",
    "# Pivot the data so each leg becomes a set of fields\n",
    "pivoted = pivot_data.pivot(index='receptacle_id', columns='leg_number')\n",
    "\n",
    "# Rename fields to match desired format\n",
    "pivoted.columns = [\n",
    "    f\"{'Flight Carrier' if col[0] == 'carrier_code' else 'Flight Number' if col[0] == 'flight_number' else 'Flight Date' if col[0] == 'flight_date_from_datetime' else 'actual_depart_datetime' if col[0] == 'actual_depart_datetime_local' else 'actual_arrive_datetime' if col[0] == 'actual_arrive_datetime_local' else col[0]} {col[1]}\" for col in pivoted.columns\n",
    "]\n",
    "\n",
    "# Reset index to make receptacle_id a field again\n",
    "pivoted = pivoted.reset_index()\n",
    "\n",
    "# Merge back with the original DataFrame (dropping duplicates to avoid row explosion)\n",
    "flight_detail_cols = [col for col in event_df.columns if (\n",
    "    col.startswith(\"Flight Carrier\") or\n",
    "    col.startswith(\"Flight Number\") or\n",
    "    col.startswith(\"Flight Date\") or\n",
    "    col.startswith(\"actual_depart_datetime\") or\n",
    "    col.startswith(\"actual_arrive_datetime\")\n",
    ")]\n",
    "\n",
    "# Drop duplicates and remove all flight detail columns dynamically\n",
    "event_df = (\n",
    "    event_df.drop_duplicates(subset='receptacle_id')\n",
    "            .drop(columns=flight_detail_cols, errors='ignore')\n",
    "            .merge(pivoted, on='receptacle_id', how='left')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce3afe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing uncessary fields\n",
    "\n",
    "# Base columns which will be the same every time\n",
    "columns_to_keep = [\n",
    "    \"receptacle_id\",\n",
    "    'fct_cgo_gls_mail_cardit_sk',\n",
    "    'last_leg_uld_id',\n",
    "    'mail_consign_number'\n",
    "]\n",
    "\n",
    "# Add all columns that match the flight detail patterns (for 1...n)\n",
    "flight_columns = [col for col in event_df.columns if (\n",
    "    col.startswith(\"Flight Carrier\") or\n",
    "    col.startswith(\"Flight Number\") or\n",
    "    col.startswith(\"Flight Date\") or\n",
    "    col.startswith(\"actual_depart_datetime\") or\n",
    "    col.startswith(\"actual_arrive_datetime\")\n",
    ")]\n",
    "\n",
    "# Combine both sets of columns\n",
    "final_columns = columns_to_keep + flight_columns\n",
    "\n",
    "event_df = event_df[final_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc68c03",
   "metadata": {},
   "source": [
    "## Merging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583607d",
   "metadata": {},
   "source": [
    "### Merging Master and Cardit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b5cffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join between master_df and cardit_df\n",
    "master_inner_cardit_df = pd.merge(master_df, cardit_df, on='dim_cgo_cargo_awb_master_sk', how='inner')\n",
    "\n",
    "# Data that failed to merged from master_df\n",
    "left_only = pd.merge(master_df, cardit_df, on='dim_cgo_cargo_awb_master_sk', how='left', indicator=True)\n",
    "master_left_unmatched_cardit_df = left_only[left_only['_merge'] == 'left_only']\n",
    "\n",
    "# Data that failed to merge from cardit_df\n",
    "right_only = pd.merge(master_df, cardit_df, on='dim_cgo_cargo_awb_master_sk', how='right', indicator=True)\n",
    "master_right_unmatched_cardit_df = right_only[right_only['_merge'] == 'right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983c5e9",
   "metadata": {},
   "source": [
    "### Merging Master Cardit and Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "683ffb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join between master_inner_cardit_df and event_df\n",
    "master_cardit_inner_event_df = pd.merge(master_inner_cardit_df, event_df, on='fct_cgo_gls_mail_cardit_sk', how='inner')\n",
    "\n",
    "# Data that failed to merge from master_inner_cardit_df\n",
    "left_only = pd.merge(master_inner_cardit_df, event_df, on='fct_cgo_gls_mail_cardit_sk', how='left', indicator=True)\n",
    "master_cardit_left_unmatched_event_df = left_only[left_only['_merge'] == 'left_only']\n",
    "\n",
    "# Data that failed to merge from event_df\n",
    "right_only = pd.merge(master_inner_cardit_df, event_df, on='fct_cgo_gls_mail_cardit_sk', how='right', indicator=True)\n",
    "master_cardit_right_unmatched_event_df = right_only[right_only['_merge'] == 'right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26cedb",
   "metadata": {},
   "source": [
    "## Post Merge Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcdbcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing uncessary fields (eg surrogate keys)\n",
    "\n",
    "master_cardit_inner_event_df.drop(columns=['receptacle_charge_weight', 'fct_cgo_gls_mail_cardit_sk', 'dim_cgo_cargo_awb_master_sk'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e97a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding the field Arrival Date: the date of the last actual_arrive_datetime_local of the last leg for each flight\n",
    "\"\"\"\n",
    "\n",
    "arrival_cols = [col for col in master_cardit_inner_event_df.columns if col.startswith('actual_arrive_datetime')]\n",
    "\n",
    "if arrival_cols:\n",
    "    master_cardit_inner_event_df['Arrival Date'] = (\n",
    "        master_cardit_inner_event_df[arrival_cols]\n",
    "        .max(axis=1)  # Get the latest datetime across the row\n",
    "        .dt.date      # Extract just the date\n",
    "    )\n",
    "else:\n",
    "    master_cardit_inner_event_df['Arrival Date'] = pd.NaT  # Fallback if no columns found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ce1d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming fields to match CNP template\n",
    "\n",
    "master_cardit_inner_event_df = master_cardit_inner_event_df.rename(columns={\n",
    "    'awb_number': 'PAWB',\n",
    "    'shipment_origin': 'Host Origin Station',\n",
    "    'shipment_dest': 'Host Destination Station',\n",
    "    'receptacle_id': 'Receptacle',\n",
    "    'last_leg_uld_id': 'Arrival ULD number',\n",
    "    'mail_consign_number': 'CARDIT',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e61f973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Reorder columns to match the CNP template\"\"\"\n",
    "\n",
    "base_before_columns = [\n",
    "    'Receptacle',\n",
    "    'PAWB',\n",
    "    'CARDIT',\n",
    "    'Host Origin Station',\n",
    "    'Host Destination Station',\n",
    "]\n",
    "\n",
    "base_after_columns = [\n",
    "    'Arrival Date',\n",
    "    'Arrival ULD number',\n",
    "]\n",
    "\n",
    "# Get all leg numbers from the flight-related columns\n",
    "import re\n",
    "\n",
    "# Extract all leg numbers present in the DataFrame\n",
    "leg_numbers = sorted(set(\n",
    "    int(re.search(r'\\d+$', col).group())\n",
    "    for col in master_cardit_inner_event_df.columns\n",
    "    if re.search(r'\\d+$', col) and (\n",
    "        col.startswith('Flight Carrier') or\n",
    "        col.startswith('Flight Number') or\n",
    "        col.startswith('Flight Date') or\n",
    "        col.startswith('actual_depart_datetime') or\n",
    "        col.startswith('actual_arrive_datetime')\n",
    "    )\n",
    "))\n",
    "\n",
    "# Build ordered flight columns\n",
    "ordered_flight_columns = []\n",
    "for n in leg_numbers:\n",
    "    ordered_flight_columns.extend([\n",
    "        f'Flight Carrier {n}',\n",
    "        f'Flight Number {n}',\n",
    "        f'Flight Date {n}',\n",
    "        f'actual_depart_datetime {n}',\n",
    "        f'actual_arrive_datetime {n}'\n",
    "    ])\n",
    "\n",
    "# Combine and reorder\n",
    "master_cardit_inner_event_df = master_cardit_inner_event_df[base_before_columns + ordered_flight_columns + base_after_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current dataframe can be exported for general usage. Contains all receptacles, their awb, cardit, o&d, flight details of all legs, depart and arrival of all legs, uld number\n",
    "# This dataframe is the final processed CX data \n",
    "master_cardit_inner_event_df.to_excel('master_cardit_inner_event_df.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a904f",
   "metadata": {},
   "source": [
    "## Merging with CNP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNP data \n",
    "cnp_df = pd.read_excel('Sample Data.xlsx', sheet_name='Raw data provided by CNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d60c5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting CNP data to allow for reading\n",
    "\n",
    "# Set row 3 as the columns\n",
    "cnp_df.columns = cnp_df.iloc[3]\n",
    "\n",
    "# Drop rows 0 to 4 (inclusive)\n",
    "cnp_df = cnp_df.drop(index=range(0, 5)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4e75e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging master_cardit_inner_event_df (cx data) with CNP data\n",
    "\n",
    "# Inner join between master_cardit_inner_event_df and cnp_df\n",
    "cx_inner_cnp_df = pd.merge(master_cardit_inner_event_df, cnp_df, on='Receptacle', how='inner')\n",
    "\n",
    "# Data that failed to merge from master_cardit_inner_event_df\n",
    "left_only = pd.merge(master_cardit_inner_event_df, cnp_df, on='Receptacle', how='left', indicator=True)\n",
    "cx_left_unmatched_cnp_df = left_only[left_only['_merge'] == 'left_only']\n",
    "\n",
    "# Data that failed to merge from cnp_df\n",
    "right_only = pd.merge(master_cardit_inner_event_df, cnp_df, on='Receptacle', how='right', indicator=True)\n",
    "cx_right_unmatched_cnp_df = right_only[right_only['_merge'] == 'right_only']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83ae4c",
   "metadata": {},
   "source": [
    "#### Adding new columns to match output 1 (internal use)\n",
    "Columns to add: \n",
    "    Number of Packet under same receptacle, \n",
    "    Tariff amount (using 80% now), \n",
    "    A column increasing from 1...n with no name (required in output 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84d8dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Packets under same receptacle (eg the same receptacle can have mulitple packets)\n",
    "cx_inner_cnp_df['Number of Packet under same receptacle'] = cx_inner_cnp_df.groupby('Receptacle')['Receptacle'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8234abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tariff amount\n",
    "\n",
    "# Ensure the column is numeric (convert if needed)\n",
    "cx_inner_cnp_df['Customs Declared Value'] = pd.to_numeric(cx_inner_cnp_df['Customs Declared Value'], errors='coerce')\n",
    "\n",
    "# Calculate Tariff amount and round to 2 decimal places\n",
    "cx_inner_cnp_df['Tariff amount'] = (cx_inner_cnp_df['Customs Declared Value'] * 0.8).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column increasing number\n",
    "cx_inner_cnp_df[''] = range(1, len(cx_inner_cnp_df) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8eaeeb",
   "metadata": {},
   "source": [
    "### Pre Export Processing Ouput 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35ce77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming fields to match CNP template\n",
    "cx_inner_cnp_df.rename(columns={\n",
    "    'Receptacle Weight': 'Bag weight',\n",
    "    'Content': 'Declared content',\n",
    "    'HS code': 'HS Code',\n",
    "    'Customs Declared Value': 'Declared Value',\n",
    "    'Receptacle': 'Receptacle',      \n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6dbc64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the fields to match CNP template\n",
    "\n",
    "# Convert all column names to strings\n",
    "cx_inner_cnp_df.columns = cx_inner_cnp_df.columns.map(str)\n",
    "\n",
    "# Define start and end columns\n",
    "start_cols = ['', 'PAWB', 'CARDIT', 'Host Origin Station', 'Host Destination Station']\n",
    "end_cols = [\n",
    "    'Arrival Date', 'Arrival ULD number', \n",
    "    'Receptacle', 'Bag weight', 'Bag Number',\n",
    "    'Tracking Number', 'Declared content', 'HS Code',\n",
    "    'Declared Value', 'Currency', 'Number of Packet under same receptacle', 'Tariff amount'\n",
    "]\n",
    "\n",
    "# Add dynamic flight-related columns (can have any number of legs) - Flight carrier 1, 2, 3... needs to be reordered dynamically\n",
    "flight_cols = [col for col in cx_inner_cnp_df.columns if any(\n",
    "    str(col).startswith(prefix) for prefix in [\n",
    "        'Flight Carrier', 'Flight Number', 'Flight Date'\n",
    "    ]\n",
    ")]\n",
    "\n",
    "# Combine and reorder. This merge\n",
    "new_order = start_cols + flight_cols + end_cols\n",
    "output_1_df = cx_inner_cnp_df[new_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6afefa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output_1_df can be exported for output 1 (internal use)\n",
    "output_1_df.to_excel('output_1_df.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d1e5b",
   "metadata": {},
   "source": [
    "### Creating Output 2 (CBP) from Output 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11eda72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Ensure column names are strings\n",
    "df = output_1_df.copy()\n",
    "df.columns = df.columns.map(str)\n",
    "\n",
    "# Map Host Destination Station to Arrival Port Code\n",
    "port_code_map = {\n",
    "    'JFK': 4701,\n",
    "    'ORD': 3901,\n",
    "    'LAX': 2720\n",
    "}\n",
    "\n",
    "# If a destination station can't be matched with an arrival port code, fill with 0\n",
    "df['Arrival Port Code'] = df['Host Destination Station'].map(port_code_map).fillna(0).astype(int)\n",
    "\n",
    "# Identify all flight leg numbers from column names\n",
    "flight_leg_nums = sorted(set(\n",
    "    int(re.search(r'\\d+$', col).group())\n",
    "    for col in df.columns\n",
    "    if re.search(r'\\d+$', col) and (\n",
    "        col.startswith('Flight Carrier') or col.startswith('Flight Number')\n",
    "    )\n",
    "))\n",
    "\n",
    "# Function to get the highest available flight leg per row\n",
    "def get_highest_leg_value(row, prefix):\n",
    "    for leg in reversed(flight_leg_nums):\n",
    "        col_name = f\"{prefix} {leg}\"\n",
    "        if col_name in row and pd.notnull(row[col_name]):\n",
    "            return row[col_name]\n",
    "    return None\n",
    "\n",
    "# Apply function to get Carrier Code and Flight Number\n",
    "df['Carrier Code'] = df.apply(lambda row: get_highest_leg_value(row, 'Flight Carrier'), axis=1)\n",
    "df['Flight/Trip Number'] = df.apply(lambda row: get_highest_leg_value(row, 'Flight Number'), axis=1)\n",
    "\n",
    "# Format Arrival Date and Declared Value\n",
    "df['Arrival Date'] = pd.to_datetime(df['Arrival Date'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "df['Declared Value (USD)'] = df['Declared Value'].apply(lambda x: f\"${x:.2f}\" if pd.notnull(x) else \"\")\n",
    "\n",
    "# Create the final dataframe\n",
    "cbp_df = df[['Carrier Code', 'Flight/Trip Number', 'Tracking Number', 'Arrival Port Code', 'Arrival Date', 'Declared Value (USD)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0e6c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cbp_df can be exported for output 1 (internal use)\n",
    "cbp_df.to_excel('cbp_df.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
